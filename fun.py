import numpy as np
import pandas as pd
from collections import *
import cPickle
import time

def calEnt(rawList):
    length = float(len(rawList))
    c = Counter(rawList)
    distribution = [v/length for v in c.values()]
    ent = 0
    for p in distribution:
        ent -= p * np.log2(p)
    return ent

def getClassFromId(id):
    return opngramMap[id]['g']
    # return label[label.Id == id].reset_index().loc[0, 'Class']

def getOpngram(opcodelist, n=3):
    opngramlist = [tuple(opcodelist[i:i+n]) for i in range(len(opcodelist)-n)]
    opngram = Counter(opngramlist)
    return opngram

'''
baseDir = "E:/msmalware/trainops/"
label = pd.read_csv("E:/msmalware/subtrain40labels2.csv")
# get ops directly from ops file (malware)
opngramMap = {}
count = 1
for id in label.Id:
    filepath = baseDir + id + ".txt"
    f = open(filepath)
    opseq = []
    for line in f:
        opseq.append(line[:-1])
    opngram = getOpngram(opseq)
    print "counting ngram of", count, "file...", opngram
    count += 1
    opngramMap[id] = opngram
'''
opngramMap = {
    "id1": Counter({'a': 1, 'b': 1, 'c': 1, 'd': 1, 'e': 1, 'f': 1, 'g': 1}),
    "id2": Counter({'a': 2, 'b': 1, 'c': 1, 'd': 1, 'e': 1, 'f': 1, 'g': 1}),
    "id3": Counter({'a': 2, 'b': 1, 'c': 1, 'd': 1, 'e': 1, 'f': 1, 'g': 1}),
    "id4": Counter({'a': 1, 'b': 1, 'c': 1, 'd': 1, 'e': 1, 'f': 1, 'g': 1}),
    "id5": Counter({'a': 3, 'b': 1, 'c': 1, 'd': 1, 'e': 1, 'f': 1, 'g': 1}),
    "id6": Counter({'a': 1, 'b': 1, 'c': 1, 'd': 1, 'e': 1, 'f': 1, 'g': 1}),
    "id7": Counter({'a': 2, 'b': 1, 'c': 1, 'd': 1, 'e': 1, 'f': 1, 'g': 1}),
    "id8": Counter({'a': 2, 'b': 1, 'c': 1, 'd': 1, 'e': 1, 'f': 1, 'g': 1}),
    "id9": Counter({'a': 2, 'b': 1, 'c': 1, 'd': 1, 'e': 1, 'f': 1, 'g': 0}),
    "id10": Counter({'a': 1, 'b': 1, 'c': 1, 'd': 1, 'e': 1, 'f': 1, 'g': 0}),
    "id11": Counter({'a': 3, 'b': 1, 'c': 1, 'd': 1, 'e': 1, 'f': 1, 'g': 0}),
    "id12": Counter({'a': 3, 'b': 1, 'c': 1, 'd': 1, 'e': 1, 'f': 1, 'g': 0}),
    "id13": Counter({'a': 1, 'b': 1, 'c': 1, 'd': 1, 'e': 1, 'f': 1, 'g': 0}),
    "id14": Counter({'a': 3, 'b': 1, 'c': 1, 'd': 1, 'e': 1, 'f': 1, 'g': 0}),
    "id15": Counter({'a': 2, 'b': 1, 'c': 1, 'd': 1, 'e': 1, 'f': 1, 'g': 0}),
    "id16": Counter({'a': 3, 'b': 1, 'c': 1, 'd': 1, 'e': 1, 'f': 1, 'g': 0}),
    "id17": Counter({'a': 1, 'b': 1, 'c': 1, 'd': 1, 'e': 1, 'f': 1, 'g': 0})
}

'''interface: opngramMap'''
# sumc = Counter()
# for v in opngramMap.values():
#     sumc += v
# features = sumc.keys()

features = set()
for v in opngramMap.values():
    features.update(v.keys())

l = len(features)
f = open("E:/log-tmp.txt", "a")
print >> f, ""
print >> f, time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(time.time()))
print >> f, "count information increase of", l, "features, sub40 v2"
f.close()

'''interface: opngramMap, features'''
d = opngramMap.keys()
draw = []
for id in d:
    draw.append(getClassFromId(id))
dent = calEnt(draw)
print "dent:", dent
featureInfoIncreMap = {}
count = 1
step = 2
'''
Each feature has a Raw Map, the Map means grouping the data by this feature.
Id List: (feature-value=v1): [2,3,7,8,9,15]
Raw list: (the classes of ids in Id list): [1,1,1,1,0,0]
distribution list: [2/3, 1/3]

then the entropy can be calculated
'''
for feature in features:
    print "counting information increase of feature", count, "in", l, "features..."
    count += 1
    partitionRawMap = defaultdict(list)
    for id in d:
        partitionRawMap[opngramMap[id][feature] / step].append(getClassFromId(id))

    partitionEntMap = {}
    for ftype, raw in partitionRawMap.iteritems():
        partitionEntMap[ftype] = tuple([calEnt(raw), len(raw) / float(len(d))])
    sumEnt = 0.0
    for v in partitionEntMap.values():
        sumEnt += np.cumprod(v)[-1]  # v[0]*v[1]
    featureInfoIncreMap[feature] = dent - sumEnt

'''result: featureInfoIncreMap'''
f = open("E:/log-tmp.txt", "a")
print >> f, time.strftime("End time: %Y-%m-%d %H:%M:%S", time.localtime(time.time()))
f.close()

df = pd.DataFrame(featureInfoIncreMap.items(), columns=['ngram', 'informationIncrease'])
df.to_csv("E:/InfoIncre.csv", index=False)

cPickle.dump(featureInfoIncreMap, open("E:/InfoIncre.p", "wb"))
